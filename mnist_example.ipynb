{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johngunerli/miniconda3/envs/gpu/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 22:57:52 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.10              Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "|  0%   38C    P8             14W /  450W |    1283MiB /  24564MiB |     26%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        31      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1\n",
      "True\n",
      "Set device to gpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(jaxon.current_device())\n",
    "print(jaxon.device_count())\n",
    "print(jaxon.cuda_is_available())\n",
    "print(jaxon.set_device(\"gpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 22:57:54.305125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jaxon import Sequential, Linear, ReLU, Conv2D, Flatten\n",
    "from jax import random\n",
    "\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = np.expand_dims(x_train, -1) / 255.0\n",
    "    x_test = np.expand_dims(x_test, -1) / 255.0\n",
    "    x_train = x_train.transpose((0, 3, 1, 2))\n",
    "    x_test = x_test.transpose((0, 3, 1, 2))\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    return jnp.array(x_train), jnp.array(y_train), jnp.array(x_test), jnp.array(y_test)\n",
    "\n",
    "\n",
    "# Maybe we can implement a DataLoader here, but for now we will just load the data w/ the function.\n",
    "x_train_jax, y_train_jax, x_test_jax, y_test_jax = load_and_preprocess_data()\n",
    "\n",
    "\n",
    "y_train_jax = y_train_jax.astype(jnp.float32)\n",
    "y_test_jax = y_test_jax.astype(jnp.float32)\n",
    "x_train_jax = x_train_jax.astype(jnp.float32)\n",
    "x_test_jax = x_test_jax.astype(jnp.float32)\n",
    "\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential(\n",
    "        Conv2D(16, (3, 3), stride=1, padding=\"SAME\"),\n",
    "        ReLU(),\n",
    "        Conv2D(32, (3, 3), stride=1, padding=\"SAME\"),\n",
    "        ReLU(),\n",
    "        Flatten(),\n",
    "        Linear(32 * 28 * 28, 10),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "rng = random.PRNGKey(0)\n",
    "input_shape = (1, 1, 28, 28)  # Example input shape for MNIST (N, C, H, W)\n",
    "model = create_cnn_model()\n",
    "output_shape, params = model.init_params(rng, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand implemented for now, we can add it directly later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.example_libraries import optimizers\n",
    "\n",
    "step_size = 0.001\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import value_and_grad\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    return -jnp.mean(jnp.sum(labels * jax.nn.log_softmax(logits), axis=1))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(opt_state, x_batch, y_batch):\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = model(x_batch, params)\n",
    "        loss = cross_entropy_loss(logits, y_batch)\n",
    "        return loss\n",
    "\n",
    "    grads = jax.grad(loss_fn)(params)\n",
    "    return opt_update(0, grads, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Training Accuracy: 0.9366, Test Accuracy: 0.9504\n",
      "Epoch 2 completed. Training Accuracy: 0.9716, Test Accuracy: 0.9823\n",
      "Epoch 3 completed. Training Accuracy: 0.9807, Test Accuracy: 0.9893\n",
      "Epoch 4 completed. Training Accuracy: 0.9846, Test Accuracy: 0.9922\n",
      "Epoch 5 completed. Training Accuracy: 0.9868, Test Accuracy: 0.9936\n",
      "Epoch 6 completed. Training Accuracy: 0.9884, Test Accuracy: 0.9933\n",
      "Epoch 7 completed. Training Accuracy: 0.9897, Test Accuracy: 0.9939\n",
      "Epoch 8 completed. Training Accuracy: 0.9906, Test Accuracy: 0.9939\n",
      "Epoch 9 completed. Training Accuracy: 0.9916, Test Accuracy: 0.9947\n",
      "Epoch 10 completed. Training Accuracy: 0.9923, Test Accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "def batch_accuracy(params, x, y):\n",
    "    logits = model(x, params)\n",
    "    pred_classes = jnp.argmax(logits, axis=1)\n",
    "    true_classes = jnp.argmax(y, axis=1)\n",
    "    accuracy = jnp.mean(pred_classes == true_classes)\n",
    "    return accuracy\n",
    "\n",
    "def compute_accuracy_over_dataset(params, x_data, y_data, batch_size):\n",
    "    num_batches = len(x_data) // batch_size\n",
    "    acc_sum = 0.0\n",
    "    for i in range(0, len(x_data), batch_size):\n",
    "        x_batch = x_data[i:i+batch_size]\n",
    "        y_batch = y_data[i:i+batch_size]\n",
    "        acc_sum += batch_accuracy(params, x_batch, y_batch)\n",
    "    return acc_sum / num_batches\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(x_train_jax), batch_size):\n",
    "        x_batch = x_train_jax[i:i+batch_size]\n",
    "        y_batch = y_train_jax[i:i+batch_size]\n",
    "        opt_state = train_step(opt_state, x_batch, y_batch)\n",
    "    \n",
    "    params = get_params(opt_state)\n",
    "    train_acc = compute_accuracy_over_dataset(params, x_train_jax, y_train_jax, batch_size)\n",
    "    test_acc = compute_accuracy_over_dataset(params, x_test_jax, y_test_jax, batch_size)\n",
    "    print(f\"Epoch {epoch + 1} completed. Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
